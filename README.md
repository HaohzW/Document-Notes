# Document-Notes

主要整理、记录文献以及学习过程中记录的笔记.

## NLP

BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding
[原文](https://arxiv.org/abs/1810.04805)
[源码](https://github.com/google-research/bert)
[笔记](https://github.com/HaohzW/Document-Notes/blob/main/NLP/BERT/note.md#bert--pre-training-of-deep-bidirectional-transformers-for-language-understanding%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0)

## Math
